{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud client library\n",
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "import sys, six\n",
    "\n",
    "# Import Data Sccience libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Instantiates a client\n",
    "client = language.LanguageServiceClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_suicide_df = pd.DataFrame.from_csv(\"sample_suicide_watch_text.csv\",encoding = \"ISO-8859-1\").iloc[0:10,:]\n",
    "\n",
    "small_suicide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_text(text):\n",
    "    \"\"\"Detects sentiment in the text.\"\"\"\n",
    "    client = language.LanguageServiceClient()\n",
    "\n",
    "    if isinstance(text, six.binary_type):\n",
    "        text = text.decode('utf-8')\n",
    "\n",
    "    # Instantiates a plain text document.\n",
    "    document = types.Document(\n",
    "        content=text,\n",
    "        type=enums.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "    # Detects sentiment in the document. You can also analyze HTML with:\n",
    "    #   document.type == enums.Document.Type.HTML\n",
    "    sentiment = client.analyze_sentiment(document).document_sentiment\n",
    "    \n",
    "    return [sentiment.score,sentiment.magnitude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_sentiment_text(text):\n",
    "    \"\"\"Detects entity sentiment in the provided text.\"\"\"\n",
    "    client = language.LanguageServiceClient()\n",
    "\n",
    "    if isinstance(text, six.binary_type):\n",
    "        text = text.decode('utf-8')\n",
    "\n",
    "    document = types.Document(\n",
    "        content=text.encode('utf-8'),\n",
    "        type=enums.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "    # Detect and send native Python encoding to receive correct word offsets.\n",
    "    encoding = enums.EncodingType.UTF32\n",
    "    if sys.maxunicode == 65535:\n",
    "        encoding = enums.EncodingType.UTF16\n",
    "\n",
    "    result = client.analyze_entity_sentiment(document, encoding)\n",
    "\n",
    "    for entity in result.entities:\n",
    "        print('Mentions: ')\n",
    "        print(u'Name: \"{}\"'.format(entity.name))\n",
    "        for mention in entity.mentions:\n",
    "            print(u'  Begin Offset : {}'.format(mention.text.begin_offset))\n",
    "            print(u'  Content : {}'.format(mention.text.content))\n",
    "            print(u'  Magnitude : {}'.format(mention.sentiment.magnitude))\n",
    "            print(u'  Sentiment : {}'.format(mention.sentiment.score))\n",
    "            print(u'  Type : {}'.format(mention.type))\n",
    "        print(u'Salience: {}'.format(entity.salience))\n",
    "        print(u'Sentiment: {}\\n'.format(entity.sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mentions: \n",
      "Name: \"words\"\n",
      "  Begin Offset : 57\n",
      "  Content : words\n",
      "  Magnitude : 0.0\n",
      "  Sentiment : 0.0\n",
      "  Type : 2\n",
      "Salience: 0.3393266499042511\n",
      "Sentiment: \n",
      "\n",
      "Mentions: \n",
      "Name: \"misconception\"\n",
      "  Begin Offset : 199\n",
      "  Content : misconception\n",
      "  Magnitude : 0.800000011920929\n",
      "  Sentiment : -0.800000011920929\n",
      "  Type : 2\n",
      "Salience: 0.19303403794765472\n",
      "Sentiment: magnitude: 1.600000023841858\n",
      "score: -0.800000011920929\n",
      "\n",
      "\n",
      "Mentions: \n",
      "Name: \"anyone\"\n",
      "  Begin Offset : 330\n",
      "  Content : anyone\n",
      "  Magnitude : 0.30000001192092896\n",
      "  Sentiment : -0.30000001192092896\n",
      "  Type : 2\n",
      "Salience: 0.09136639535427094\n",
      "Sentiment: magnitude: 0.699999988079071\n",
      "score: -0.30000001192092896\n",
      "\n",
      "\n",
      "Mentions: \n",
      "Name: \"attention\"\n",
      "  Begin Offset : 144\n",
      "  Content : attention\n",
      "  Magnitude : 0.0\n",
      "  Sentiment : 0.0\n",
      "  Type : 2\n",
      "Salience: 0.09088879823684692\n",
      "Sentiment: \n",
      "\n",
      "Mentions: \n",
      "Name: \"pain\"\n",
      "  Begin Offset : 218\n",
      "  Content : pain\n",
      "  Magnitude : 0.20000000298023224\n",
      "  Sentiment : -0.20000000298023224\n",
      "  Type : 2\n",
      "Salience: 0.05292052775621414\n",
      "Sentiment: magnitude: 0.20000000298023224\n",
      "score: -0.20000000298023224\n",
      "\n",
      "\n",
      "Mentions: \n",
      "Name: \"feelings\"\n",
      "  Begin Offset : 240\n",
      "  Content : feelings\n",
      "  Magnitude : 0.6000000238418579\n",
      "  Sentiment : -0.6000000238418579\n",
      "  Type : 2\n",
      "Salience: 0.04622408002614975\n",
      "Sentiment: magnitude: 0.6000000238418579\n",
      "score: -0.6000000238418579\n",
      "\n",
      "\n",
      "Mentions: \n",
      "Name: \"assumption\"\n",
      "  Begin Offset : 188\n",
      "  Content : assumption\n",
      "  Magnitude : 0.10000000149011612\n",
      "  Sentiment : -0.10000000149011612\n",
      "  Type : 2\n",
      "Salience: 0.04348456487059593\n",
      "Sentiment: magnitude: 0.10000000149011612\n",
      "score: -0.10000000149011612\n",
      "\n",
      "\n",
      "Mentions: \n",
      "Name: \"feelings\"\n",
      "  Begin Offset : 477\n",
      "  Content : feelings\n",
      "  Magnitude : 0.20000000298023224\n",
      "  Sentiment : -0.20000000298023224\n",
      "  Type : 2\n",
      "Salience: 0.033725421875715256\n",
      "Sentiment: magnitude: 0.20000000298023224\n",
      "score: -0.20000000298023224\n",
      "\n",
      "\n",
      "Mentions: \n",
      "Name: \"persistence\"\n",
      "  Begin Offset : 444\n",
      "  Content : persistence\n",
      "  Magnitude : 0.8999999761581421\n",
      "  Sentiment : -0.8999999761581421\n",
      "  Type : 2\n",
      "Salience: 0.029522333294153214\n",
      "Sentiment: magnitude: 0.8999999761581421\n",
      "score: -0.8999999761581421\n",
      "\n",
      "\n",
      "Mentions: \n",
      "Name: \"ideations\"\n",
      "  Begin Offset : 486\n",
      "  Content : ideations\n",
      "  Magnitude : 0.10000000149011612\n",
      "  Sentiment : -0.10000000149011612\n",
      "  Type : 2\n",
      "Salience: 0.029522333294153214\n",
      "Sentiment: magnitude: 0.10000000149011612\n",
      "score: -0.10000000149011612\n",
      "\n",
      "\n",
      "Mentions: \n",
      "Name: \"thoughts\"\n",
      "  Begin Offset : 468\n",
      "  Content : thoughts\n",
      "  Magnitude : 0.4000000059604645\n",
      "  Sentiment : -0.4000000059604645\n",
      "  Type : 2\n",
      "Salience: 0.029522333294153214\n",
      "Sentiment: magnitude: 0.4000000059604645\n",
      "score: -0.4000000059604645\n",
      "\n",
      "\n",
      "Mentions: \n",
      "Name: \"myself.\"\n",
      "  Begin Offset : 519\n",
      "  Content : myself.\n",
      "  Magnitude : 0.0\n",
      "  Sentiment : 0.0\n",
      "  Type : 2\n",
      "Salience: 0.020462526008486748\n",
      "Sentiment: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "entity_sentiment_text(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_data = []\n",
    "\n",
    "for record in small_suicide_df.iterrows():\n",
    "    text = record[1][\"text\"]\n",
    "    \n",
    "    extra_record = sentiment_text(text)\n",
    "    extra_data.append(extra_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_data_df = pd.DataFrame(extra_data, columns=[\"Score\",\"Magnitude\"],index=small_suicide_df.index)\n",
    "\n",
    "extra_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_combined_df = small_suicide_df.join(extra_data_df)\n",
    "\n",
    "small_combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "depression_df = pd.DataFrame.from_csv(\"depressionTrainingSet3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep500_df = depression_df.iloc[0:500,0:1].reset_index()\n",
    "\n",
    "dep500_extra = []\n",
    "\n",
    "for record in dep500_df.iterrows():\n",
    "    text = record[1][\"text\"]\n",
    "    \n",
    "    extra_record = sentiment_text(text)\n",
    "    dep500_extra.append(extra_record)\n",
    "\n",
    "dep500_extra_df = pd.DataFrame(dep500_extra,columns=[\"sentiment\",\"magnitude\"])\n",
    "\n",
    "dep500_extra_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "big_dep500_df = dep500_df.join(dep500_extra_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = big_dep500_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 2)\n"
     ]
    }
   ],
   "source": [
    "nodepression_df = pd.DataFrame.from_csv(\"depressionTrainingSet4.csv\")\n",
    "nodep500_df = nodepression_df.iloc[0:500,0:1].reset_index()\n",
    "\n",
    "nodep500_extra = []\n",
    "print(nodep500_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for record in nodep500_df.iterrows():\n",
    "    text = record[1][\"text\"][0:999]\n",
    "    \n",
    "    extra_record = sentiment_text(text)\n",
    "    nodep500_extra.append(extra_record)\n",
    "\n",
    "nodep500_extra_df = pd.DataFrame(nodep500_extra,columns=[\"sentiment\",\"magnitude\"])\n",
    "\n",
    "nodep500_extra_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodep500 = nodep500_df.join(nodep500_extra_df)\n",
    "\n",
    "training_data = pd.concat([big_dep500_df, all_nodep500])\n",
    "\n",
    "training_data.to_csv(\"training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start doing classification with SKlearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_data.loc[:,[\"sentiment\",\"magnitude\"]]\n",
    "y = training_data.loc[:,\"risk_of_suicide\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Score: 0.780\tMSE:-0.220\n"
     ]
    }
   ],
   "source": [
    "regr = LogisticRegression()\n",
    "\n",
    "score = cross_val_score(regr,X,y)\n",
    "mse = cross_val_score(regr,X,y,scoring=\"neg_mean_squared_error\")\n",
    "print(f\"Logistic Regression:\\nScore: {score.mean():.3f}\\tMSE:{mse.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-DTC with max_depth 02:\tScore:0.725\tMSE:-0.275\n",
      "B-DTC with max_depth 03:\tScore:0.707\tMSE:-0.293\n",
      "B-DTC with max_depth 04:\tScore:0.699\tMSE:-0.302\n",
      "B-DTC with max_depth 05:\tScore:0.705\tMSE:-0.290\n",
      "B-DTC with max_depth 06:\tScore:0.706\tMSE:-0.312\n",
      "B-DTC with max_depth 07:\tScore:0.702\tMSE:-0.301\n",
      "B-DTC with max_depth 08:\tScore:0.705\tMSE:-0.297\n",
      "B-DTC with max_depth 09:\tScore:0.690\tMSE:-0.300\n",
      "B-DTC with max_depth 10:\tScore:0.698\tMSE:-0.311\n",
      "B-DTC with max_depth 11:\tScore:0.708\tMSE:-0.296\n",
      "B-DTC with max_depth 12:\tScore:0.700\tMSE:-0.301\n",
      "B-DTC with max_depth 13:\tScore:0.699\tMSE:-0.292\n",
      "B-DTC with max_depth 14:\tScore:0.700\tMSE:-0.298\n",
      "B-DTC with max_depth 15:\tScore:0.704\tMSE:-0.297\n",
      "B-DTC with max_depth 16:\tScore:0.700\tMSE:-0.302\n",
      "B-DTC with max_depth 17:\tScore:0.697\tMSE:-0.289\n",
      "B-DTC with max_depth 18:\tScore:0.698\tMSE:-0.292\n",
      "B-DTC with max_depth 19:\tScore:0.707\tMSE:-0.304\n",
      "B-DTC with max_depth 20:\tScore:0.700\tMSE:-0.283\n",
      "B-DTC with max_depth 21:\tScore:0.711\tMSE:-0.291\n",
      "B-DTC with max_depth 22:\tScore:0.719\tMSE:-0.296\n",
      "B-DTC with max_depth 23:\tScore:0.688\tMSE:-0.292\n",
      "B-DTC with max_depth 24:\tScore:0.708\tMSE:-0.294\n",
      "B-DTC with max_depth 25:\tScore:0.697\tMSE:-0.284\n"
     ]
    }
   ],
   "source": [
    "for depth in range(2,26):\n",
    "    boosted_dtc = AdaBoostClassifier(DecisionTreeClassifier(max_depth=depth))\n",
    "    boosted_dtc.fit(X,y)\n",
    "    currScore = cross_val_score(boosted_dtc,X,y)\n",
    "    currMSE = cross_val_score(boosted_dtc,X,y,scoring=\"neg_mean_squared_error\")\n",
    "    print(f\"B-DTC with max_depth {depth:02d}:\\tScore: {currScore.mean():.3f}\\tMSE: {currMSE.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_sentiment(text):\n",
    "    client = language.LanguageServiceClient()\n",
    "\n",
    "    if isinstance(text, six.binary_type):\n",
    "        text = text.decode('utf-8')\n",
    "\n",
    "    document = types.Document(\n",
    "            content=text.encode('utf-8'),\n",
    "            type=enums.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "    # Detect and send native Python encoding to receive correct word offsets.\n",
    "    encoding = enums.EncodingType.UTF32\n",
    "    if sys.maxunicode == 65535:\n",
    "        encoding = enums.EncodingType.UTF16\n",
    "\n",
    "    result = client.analyze_entity_sentiment(document, encoding)\n",
    "\n",
    "    salience_ls = [[] for x in range(8)]\n",
    "    score_ls = [[] for x in range(8)]\n",
    "    magnitude_ls = [[] for x in range(8)]\n",
    "\n",
    "    for entity in result.entities:\n",
    "        salience_ls[entity.type].append(entity.salience)\n",
    "        score_ls[entity.type].append(entity.sentiment.score)\n",
    "        magnitude_ls[entity.type].append(entity.sentiment.magnitude)\n",
    "\n",
    "    mean_salience_ls = [sum(x)/len(x) if x else 0 for x in salience_ls]\n",
    "    mean_score_ls = [sum(x)/len(x) if x else 0 for x in score_ls]\n",
    "    mean_magnitude_ls = [sum(x)/len(x) if x else 0 for x in score_ls]\n",
    "\n",
    "    all_ls = mean_salience_ls + mean_score_ls + mean_magnitude_ls\n",
    "    return all_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_training_data = []\n",
    "for record in training_data.iterrows():\n",
    "    text = record[1][\"text\"][0:999]\n",
    "    \n",
    "    extra_record = get_entity_sentiment(text)\n",
    "    extra_training_data.append(extra_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_ls = [\"UNKNOWN\",\n",
    "      \"PERSON\",\n",
    "      \"LOCATION\",\n",
    "      \"ORGANIZATION\",\n",
    "      \"EVENT\",\n",
    "      \"WORK_OF_ART\",\n",
    "      \"CONSUMER_GOOD\",\n",
    "      \"OTHER\"\n",
    "     ]\n",
    "\n",
    "ls = [\"salience\",\"sentiment\",\"magnitude\"]\n",
    "\n",
    "together = []\n",
    "\n",
    "for x in ls:\n",
    "    for y in type_ls:\n",
    "        together.append(y+\"_\"+x)\n",
    "\n",
    "extra_training_data_df = pd.DataFrame(extra_training_data,columns=together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.index = extra_training_data_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 28)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_training_data = training_data.join(extra_training_data_df)\n",
    "extended_training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should yield better performance\n",
    "\n",
    "X = extended_training_data.loc[:,\"sentiment\":]\n",
    "y = extended_training_data.loc[:,\"risk_of_suicide\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-DTC with max_depth 02:\tScore: 0.746\tMSE: -0.253\n",
      "B-DTC with max_depth 03:\tScore: 0.734\tMSE: -0.270\n",
      "B-DTC with max_depth 04:\tScore: 0.780\tMSE: -0.240\n",
      "B-DTC with max_depth 05:\tScore: 0.752\tMSE: -0.239\n",
      "B-DTC with max_depth 06:\tScore: 0.763\tMSE: -0.238\n",
      "B-DTC with max_depth 07:\tScore: 0.753\tMSE: -0.241\n",
      "B-DTC with max_depth 08:\tScore: 0.778\tMSE: -0.247\n",
      "B-DTC with max_depth 09:\tScore: 0.751\tMSE: -0.253\n",
      "B-DTC with max_depth 10:\tScore: 0.755\tMSE: -0.261\n",
      "B-DTC with max_depth 11:\tScore: 0.746\tMSE: -0.255\n",
      "B-DTC with max_depth 12:\tScore: 0.763\tMSE: -0.246\n",
      "B-DTC with max_depth 13:\tScore: 0.759\tMSE: -0.248\n",
      "B-DTC with max_depth 14:\tScore: 0.747\tMSE: -0.242\n",
      "B-DTC with max_depth 15:\tScore: 0.755\tMSE: -0.238\n",
      "B-DTC with max_depth 16:\tScore: 0.755\tMSE: -0.237\n",
      "B-DTC with max_depth 17:\tScore: 0.757\tMSE: -0.250\n",
      "B-DTC with max_depth 18:\tScore: 0.741\tMSE: -0.266\n",
      "B-DTC with max_depth 19:\tScore: 0.747\tMSE: -0.256\n",
      "B-DTC with max_depth 20:\tScore: 0.753\tMSE: -0.257\n",
      "B-DTC with max_depth 21:\tScore: 0.727\tMSE: -0.273\n",
      "B-DTC with max_depth 22:\tScore: 0.731\tMSE: -0.251\n",
      "B-DTC with max_depth 23:\tScore: 0.751\tMSE: -0.258\n",
      "B-DTC with max_depth 24:\tScore: 0.745\tMSE: -0.268\n",
      "B-DTC with max_depth 25:\tScore: 0.742\tMSE: -0.268\n"
     ]
    }
   ],
   "source": [
    "for depth in range(2,26):\n",
    "    boosted_dtc = AdaBoostClassifier(DecisionTreeClassifier(max_depth=depth))\n",
    "    currScore = cross_val_score(boosted_dtc,X,y)\n",
    "    currMSE = cross_val_score(boosted_dtc,X,y,scoring=\"neg_mean_squared_error\")\n",
    "    print(f\"B-DTC with max_depth {depth:02d}:\\tScore: {currScore.mean():.3f}\\tMSE: {currMSE.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Score: 0.779\tMSE:-0.221\n"
     ]
    }
   ],
   "source": [
    "regr = LogisticRegression()\n",
    "regr.fit(X,y)\n",
    "score = cross_val_score(regr,X,y)\n",
    "mse = cross_val_score(regr,X,y,scoring=\"neg_mean_squared_error\")\n",
    "print(f\"Logistic Regression:\\nScore: {score.mean():.3f}\\tMSE:{mse.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 26)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"I hate myself, I'm going to kill myself, this day is terrible. What am I doing with my life???\"\n",
    "text2 = \"What a beautiful day, I feel so happy!\"\n",
    "text3 = \"It is not a lack of love, but a lack of friendship that makes unhappy marriages.\"\n",
    "text4 = \"Whoever fights monsters should see to it that in the process he does not become a monster. And if you gaze long enough into an abyss, the abyss will gaze back into you.\"\n",
    "text5 = \"God is dead. God remains dead. And we have killed him. Yet his shadow still looms. How shall we comfort ourselves, the murderers of all murderers? What was holiest and mightiest of all that the world has yet owned has bled to death under our knives; who will wipe this blood off us? What water is there for us to clean ourselves?\"\n",
    "text6 = \"I will not let my depression take over, since this would left everyone i know in sorrow!\"\n",
    "\n",
    "text_ls = [text1,text2,text3,text4,text5,text6]\n",
    "# I would personally say 1,0,0,?,1\n",
    "\n",
    "data = np.array([sentiment_text(text) + get_entity_sentiment(text) for text in text_ls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_dtc = AdaBoostClassifier(DecisionTreeClassifier(max_depth=4))\n",
    "boosted_dtc.fit(X,y)\n",
    "boosted_dtc.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>risk_of_suicide</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm 25, college grad, engineer, fiancee, 50k s...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.014683</td>\n",
       "      <td>0.272605</td>\n",
       "      <td>0.486469</td>\n",
       "      <td>0.212976</td>\n",
       "      <td>0.013268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ive been having the worst time of my life thes...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.006734</td>\n",
       "      <td>0.489428</td>\n",
       "      <td>0.444820</td>\n",
       "      <td>0.053174</td>\n",
       "      <td>0.005844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Because when you fall back down again you reme...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.201178</td>\n",
       "      <td>0.192354</td>\n",
       "      <td>0.034518</td>\n",
       "      <td>0.042073</td>\n",
       "      <td>0.529877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Yay I wasted a whole year of being alive!! Thi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.008009</td>\n",
       "      <td>0.703660</td>\n",
       "      <td>0.231973</td>\n",
       "      <td>0.052193</td>\n",
       "      <td>0.004165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I have no friends. No one likes me. I hate mys...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.049800</td>\n",
       "      <td>0.180501</td>\n",
       "      <td>0.687282</td>\n",
       "      <td>0.072260</td>\n",
       "      <td>0.010157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Literally, everything I've ever done has ended...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.051445</td>\n",
       "      <td>0.569158</td>\n",
       "      <td>0.216701</td>\n",
       "      <td>0.151320</td>\n",
       "      <td>0.011376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>I don't usually post these \"woe is me\" type po...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.026719</td>\n",
       "      <td>0.777159</td>\n",
       "      <td>0.133978</td>\n",
       "      <td>0.041036</td>\n",
       "      <td>0.021108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Found this quote in a book I read over Thanksg...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.035380</td>\n",
       "      <td>0.606366</td>\n",
       "      <td>0.245637</td>\n",
       "      <td>0.089212</td>\n",
       "      <td>0.023405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>My mum is losing it at me, but she does any ti...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.027490</td>\n",
       "      <td>0.262430</td>\n",
       "      <td>0.417277</td>\n",
       "      <td>0.287696</td>\n",
       "      <td>0.005106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Really feeling out of it, like really dissocia...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.050468</td>\n",
       "      <td>0.477498</td>\n",
       "      <td>0.137695</td>\n",
       "      <td>0.313891</td>\n",
       "      <td>0.020448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>My whole life I've been told that I'm smart. A...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>0.139498</td>\n",
       "      <td>0.061616</td>\n",
       "      <td>0.651178</td>\n",
       "      <td>0.062731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Jesus. How do I even start. All of this is so ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.059546</td>\n",
       "      <td>0.308779</td>\n",
       "      <td>0.155300</td>\n",
       "      <td>0.460811</td>\n",
       "      <td>0.015564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Im 24 and I have no friends. I should be going...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.060098</td>\n",
       "      <td>0.403005</td>\n",
       "      <td>0.194876</td>\n",
       "      <td>0.314510</td>\n",
       "      <td>0.027510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>I've tried to type out my feelings in here for...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.183494</td>\n",
       "      <td>0.480446</td>\n",
       "      <td>0.101902</td>\n",
       "      <td>0.099603</td>\n",
       "      <td>0.134555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>It's been over two and a half years since you ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.024443</td>\n",
       "      <td>0.583278</td>\n",
       "      <td>0.303529</td>\n",
       "      <td>0.083015</td>\n",
       "      <td>0.005735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>but I don't want to kill myself.I look around ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.062365</td>\n",
       "      <td>0.204949</td>\n",
       "      <td>0.469031</td>\n",
       "      <td>0.139498</td>\n",
       "      <td>0.124157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>\"Just be more positive, you're too negative ab...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.061210</td>\n",
       "      <td>0.213844</td>\n",
       "      <td>0.565018</td>\n",
       "      <td>0.147798</td>\n",
       "      <td>0.012130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>to be able to work 8 hours per day ,to work ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.538784</td>\n",
       "      <td>0.126322</td>\n",
       "      <td>0.295618</td>\n",
       "      <td>0.009865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>I'm tired of being used. If I died, Everything...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.064522</td>\n",
       "      <td>0.673272</td>\n",
       "      <td>0.128043</td>\n",
       "      <td>0.059210</td>\n",
       "      <td>0.074954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>(im not english, my grammar may be bad)So, i j...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.042335</td>\n",
       "      <td>0.167556</td>\n",
       "      <td>0.230380</td>\n",
       "      <td>0.528680</td>\n",
       "      <td>0.031049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>I got no one to tell them goodnight. To anyone...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.061712</td>\n",
       "      <td>0.371595</td>\n",
       "      <td>0.222621</td>\n",
       "      <td>0.336222</td>\n",
       "      <td>0.007850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>I'm hopeless, lonely, stupid and all. I just g...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.019097</td>\n",
       "      <td>0.452089</td>\n",
       "      <td>0.300201</td>\n",
       "      <td>0.199263</td>\n",
       "      <td>0.029350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Does anyone else ever get wrapped up in existe...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.334307</td>\n",
       "      <td>0.633077</td>\n",
       "      <td>0.024290</td>\n",
       "      <td>0.001627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Am i the only one that gets frustrated because...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.596283</td>\n",
       "      <td>0.378771</td>\n",
       "      <td>0.018904</td>\n",
       "      <td>0.000851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>I dont wanna live for others sake, just so the...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.073941</td>\n",
       "      <td>0.425250</td>\n",
       "      <td>0.088892</td>\n",
       "      <td>0.370677</td>\n",
       "      <td>0.041240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Well, probably it isnt first one,but first off...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.436167</td>\n",
       "      <td>0.238800</td>\n",
       "      <td>0.065062</td>\n",
       "      <td>0.199143</td>\n",
       "      <td>0.060828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Hey there my depressed babes! I just wanted to...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.049648</td>\n",
       "      <td>0.647481</td>\n",
       "      <td>0.119636</td>\n",
       "      <td>0.141679</td>\n",
       "      <td>0.041556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>2017 has been the worst year of my life. Witho...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.051996</td>\n",
       "      <td>0.646988</td>\n",
       "      <td>0.176949</td>\n",
       "      <td>0.102591</td>\n",
       "      <td>0.021476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Hi everyone. First time poster. Trying not to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.009188</td>\n",
       "      <td>0.717626</td>\n",
       "      <td>0.201197</td>\n",
       "      <td>0.064610</td>\n",
       "      <td>0.007379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>I feel like all my peers already have friends ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.088471</td>\n",
       "      <td>0.568518</td>\n",
       "      <td>0.167965</td>\n",
       "      <td>0.142541</td>\n",
       "      <td>0.032504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>469</td>\n",
       "      <td>Something I found funny about this episode was...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.226345</td>\n",
       "      <td>0.453557</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.102569</td>\n",
       "      <td>0.120978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>470</td>\n",
       "      <td>&gt;THE KERKOVICH FAMILY GETS TOGETHER FOR A BIG ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.024619</td>\n",
       "      <td>0.319559</td>\n",
       "      <td>0.217760</td>\n",
       "      <td>0.066033</td>\n",
       "      <td>0.372028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>471</td>\n",
       "      <td>Wasn't she like some high-management on a big ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.282712</td>\n",
       "      <td>0.323941</td>\n",
       "      <td>0.188605</td>\n",
       "      <td>0.130815</td>\n",
       "      <td>0.073927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>472</td>\n",
       "      <td>So, as you may or may not know, we're not doin...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.216906</td>\n",
       "      <td>0.283249</td>\n",
       "      <td>0.148018</td>\n",
       "      <td>0.320100</td>\n",
       "      <td>0.031727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>473</td>\n",
       "      <td>it gives me hope for the future, hahahabut to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.054085</td>\n",
       "      <td>0.187604</td>\n",
       "      <td>0.345982</td>\n",
       "      <td>0.374047</td>\n",
       "      <td>0.038281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>474</td>\n",
       "      <td>https://docs.google.com/document/d/1yi6HwzhuCa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014982</td>\n",
       "      <td>0.176592</td>\n",
       "      <td>0.638532</td>\n",
       "      <td>0.161602</td>\n",
       "      <td>0.008292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>475</td>\n",
       "      <td>Does anyone know where to find a gif of this s...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.199953</td>\n",
       "      <td>0.345909</td>\n",
       "      <td>0.357932</td>\n",
       "      <td>0.083776</td>\n",
       "      <td>0.012430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>476</td>\n",
       "      <td>http://screenrant.com/happy-endings-b-apartmen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129444</td>\n",
       "      <td>0.017993</td>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.042180</td>\n",
       "      <td>0.803837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>477</td>\n",
       "      <td>From her twitter:\"Guest hosting Chelsea Lately...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.145472</td>\n",
       "      <td>0.536014</td>\n",
       "      <td>0.227824</td>\n",
       "      <td>0.065264</td>\n",
       "      <td>0.025427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>478</td>\n",
       "      <td>&gt;PENNY MEETS A GREAT GUY, BUT HER PRESCRIPTION...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.157751</td>\n",
       "      <td>0.347512</td>\n",
       "      <td>0.203086</td>\n",
       "      <td>0.233245</td>\n",
       "      <td>0.058406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>479</td>\n",
       "      <td>[Last night's ratings](http://tvbythenumbers.z...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.077426</td>\n",
       "      <td>0.386659</td>\n",
       "      <td>0.123421</td>\n",
       "      <td>0.076374</td>\n",
       "      <td>0.336120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>480</td>\n",
       "      <td>&gt;Alex and Dave host Thanksgiving dinner at the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.138783</td>\n",
       "      <td>0.371111</td>\n",
       "      <td>0.143072</td>\n",
       "      <td>0.223867</td>\n",
       "      <td>0.123167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>481</td>\n",
       "      <td>Ed Begley Jr is giving a talk at my school, an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.084749</td>\n",
       "      <td>0.347367</td>\n",
       "      <td>0.368720</td>\n",
       "      <td>0.173133</td>\n",
       "      <td>0.026031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>482</td>\n",
       "      <td>&gt;Max has been working the Bar Mitzvah circuit ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.629345</td>\n",
       "      <td>0.112256</td>\n",
       "      <td>0.037902</td>\n",
       "      <td>0.112679</td>\n",
       "      <td>0.107818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>483</td>\n",
       "      <td>&gt; Dave and Alex go apartment hunting, but thei...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.038629</td>\n",
       "      <td>0.441958</td>\n",
       "      <td>0.100429</td>\n",
       "      <td>0.061052</td>\n",
       "      <td>0.357933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>484</td>\n",
       "      <td>What I noticed while watching Happy Endings is...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.177702</td>\n",
       "      <td>0.275603</td>\n",
       "      <td>0.288981</td>\n",
       "      <td>0.232603</td>\n",
       "      <td>0.025111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>485</td>\n",
       "      <td>SEASON PREMIERE TONIGHT!&gt; Dave and Alex start ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.417982</td>\n",
       "      <td>0.204106</td>\n",
       "      <td>0.130964</td>\n",
       "      <td>0.038363</td>\n",
       "      <td>0.208586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>486</td>\n",
       "      <td>Casey Wilson and Adam Pally guest on todays \"C...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.018274</td>\n",
       "      <td>0.101767</td>\n",
       "      <td>0.043850</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.829140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>487</td>\n",
       "      <td>Showed up in my torrent feed! Pleasantly surpr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.191620</td>\n",
       "      <td>0.332668</td>\n",
       "      <td>0.187891</td>\n",
       "      <td>0.047858</td>\n",
       "      <td>0.239964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>488</td>\n",
       "      <td>This should be great, the one they did last ye...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.345890</td>\n",
       "      <td>0.326695</td>\n",
       "      <td>0.182883</td>\n",
       "      <td>0.056411</td>\n",
       "      <td>0.088121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>489</td>\n",
       "      <td>Hi Happy Endings peeps!I just recently became ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.011341</td>\n",
       "      <td>0.102522</td>\n",
       "      <td>0.460356</td>\n",
       "      <td>0.367947</td>\n",
       "      <td>0.057835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>490</td>\n",
       "      <td>... Does anyone know when it comes back?</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.128167</td>\n",
       "      <td>0.329880</td>\n",
       "      <td>0.212914</td>\n",
       "      <td>0.291795</td>\n",
       "      <td>0.037243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>491</td>\n",
       "      <td>In \"Makin' Changes!\" we know that Brad and Jan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.120970</td>\n",
       "      <td>0.130780</td>\n",
       "      <td>0.170057</td>\n",
       "      <td>0.457238</td>\n",
       "      <td>0.120955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>492</td>\n",
       "      <td>So Amazon has a season 1 &amp; 2 bundle going on s...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.124256</td>\n",
       "      <td>0.339024</td>\n",
       "      <td>0.298539</td>\n",
       "      <td>0.132929</td>\n",
       "      <td>0.105252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>493</td>\n",
       "      <td>So Happy Endings has become a bit of an obses...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.436171</td>\n",
       "      <td>0.155832</td>\n",
       "      <td>0.250386</td>\n",
       "      <td>0.062061</td>\n",
       "      <td>0.095551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>494</td>\n",
       "      <td>I just finished watching all episodes in a cou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.171235</td>\n",
       "      <td>0.409216</td>\n",
       "      <td>0.250323</td>\n",
       "      <td>0.134029</td>\n",
       "      <td>0.035197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>495</td>\n",
       "      <td>Unaired Season 2 episode that broadcast in the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.148147</td>\n",
       "      <td>0.243434</td>\n",
       "      <td>0.391175</td>\n",
       "      <td>0.182366</td>\n",
       "      <td>0.034877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>496</td>\n",
       "      <td>I'm pretty sure it's not available on Netflix....</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.005048</td>\n",
       "      <td>0.992009</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>497</td>\n",
       "      <td>If you have a problem with this post, you can ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.049393</td>\n",
       "      <td>0.587351</td>\n",
       "      <td>0.265013</td>\n",
       "      <td>0.083078</td>\n",
       "      <td>0.015165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>498</td>\n",
       "      <td>You guys probably get this a lot but i just go...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.464954</td>\n",
       "      <td>0.134678</td>\n",
       "      <td>0.199333</td>\n",
       "      <td>0.134869</td>\n",
       "      <td>0.066167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                               text  \\\n",
       "0        0  I'm 25, college grad, engineer, fiancee, 50k s...   \n",
       "1        1  Ive been having the worst time of my life thes...   \n",
       "2        2  Because when you fall back down again you reme...   \n",
       "3        3  Yay I wasted a whole year of being alive!! Thi...   \n",
       "4        4  I have no friends. No one likes me. I hate mys...   \n",
       "5        5  Literally, everything I've ever done has ended...   \n",
       "6        6  I don't usually post these \"woe is me\" type po...   \n",
       "7        7  Found this quote in a book I read over Thanksg...   \n",
       "8        8  My mum is losing it at me, but she does any ti...   \n",
       "9        9  Really feeling out of it, like really dissocia...   \n",
       "10      10  My whole life I've been told that I'm smart. A...   \n",
       "11      11  Jesus. How do I even start. All of this is so ...   \n",
       "12      12  Im 24 and I have no friends. I should be going...   \n",
       "13      13  I've tried to type out my feelings in here for...   \n",
       "14      14  It's been over two and a half years since you ...   \n",
       "15      15  but I don't want to kill myself.I look around ...   \n",
       "16      16  \"Just be more positive, you're too negative ab...   \n",
       "17      17  to be able to work 8 hours per day ,to work ha...   \n",
       "18      18  I'm tired of being used. If I died, Everything...   \n",
       "19      19  (im not english, my grammar may be bad)So, i j...   \n",
       "20      20  I got no one to tell them goodnight. To anyone...   \n",
       "21      21  I'm hopeless, lonely, stupid and all. I just g...   \n",
       "22      22  Does anyone else ever get wrapped up in existe...   \n",
       "23      23  Am i the only one that gets frustrated because...   \n",
       "24      24  I dont wanna live for others sake, just so the...   \n",
       "25      25  Well, probably it isnt first one,but first off...   \n",
       "26      26  Hey there my depressed babes! I just wanted to...   \n",
       "27      27  2017 has been the worst year of my life. Witho...   \n",
       "28      28  Hi everyone. First time poster. Trying not to ...   \n",
       "29      29  I feel like all my peers already have friends ...   \n",
       "..     ...                                                ...   \n",
       "969    469  Something I found funny about this episode was...   \n",
       "970    470  >THE KERKOVICH FAMILY GETS TOGETHER FOR A BIG ...   \n",
       "971    471  Wasn't she like some high-management on a big ...   \n",
       "972    472  So, as you may or may not know, we're not doin...   \n",
       "973    473  it gives me hope for the future, hahahabut to ...   \n",
       "974    474  https://docs.google.com/document/d/1yi6HwzhuCa...   \n",
       "975    475  Does anyone know where to find a gif of this s...   \n",
       "976    476  http://screenrant.com/happy-endings-b-apartmen...   \n",
       "977    477  From her twitter:\"Guest hosting Chelsea Lately...   \n",
       "978    478  >PENNY MEETS A GREAT GUY, BUT HER PRESCRIPTION...   \n",
       "979    479  [Last night's ratings](http://tvbythenumbers.z...   \n",
       "980    480  >Alex and Dave host Thanksgiving dinner at the...   \n",
       "981    481  Ed Begley Jr is giving a talk at my school, an...   \n",
       "982    482  >Max has been working the Bar Mitzvah circuit ...   \n",
       "983    483  > Dave and Alex go apartment hunting, but thei...   \n",
       "984    484  What I noticed while watching Happy Endings is...   \n",
       "985    485  SEASON PREMIERE TONIGHT!> Dave and Alex start ...   \n",
       "986    486  Casey Wilson and Adam Pally guest on todays \"C...   \n",
       "987    487  Showed up in my torrent feed! Pleasantly surpr...   \n",
       "988    488  This should be great, the one they did last ye...   \n",
       "989    489  Hi Happy Endings peeps!I just recently became ...   \n",
       "990    490          ... Does anyone know when it comes back?    \n",
       "991    491  In \"Makin' Changes!\" we know that Brad and Jan...   \n",
       "992    492  So Amazon has a season 1 & 2 bundle going on s...   \n",
       "993    493   So Happy Endings has become a bit of an obses...   \n",
       "994    494  I just finished watching all episodes in a cou...   \n",
       "995    495  Unaired Season 2 episode that broadcast in the...   \n",
       "996    496  I'm pretty sure it's not available on Netflix....   \n",
       "997    497  If you have a problem with this post, you can ...   \n",
       "998    498  You guys probably get this a lot but i just go...   \n",
       "\n",
       "     risk_of_suicide  sentiment  magnitude       joy   sadness     anger  \\\n",
       "0                  1       -0.1        2.8  0.014683  0.272605  0.486469   \n",
       "1                  1       -0.5        3.2  0.006734  0.489428  0.444820   \n",
       "2                  1       -0.3        0.6  0.201178  0.192354  0.034518   \n",
       "3                  1        0.5        1.1  0.008009  0.703660  0.231973   \n",
       "4                  1       -0.6        2.4  0.049800  0.180501  0.687282   \n",
       "5                  1       -0.5        3.4  0.051445  0.569158  0.216701   \n",
       "6                  1       -0.2        4.4  0.026719  0.777159  0.133978   \n",
       "7                  1       -0.7        1.5  0.035380  0.606366  0.245637   \n",
       "8                  1        0.0        1.2  0.027490  0.262430  0.417277   \n",
       "9                  1        0.0        3.1  0.050468  0.477498  0.137695   \n",
       "10                 1        0.1        4.2  0.084977  0.139498  0.061616   \n",
       "11                 1       -0.2        8.0  0.059546  0.308779  0.155300   \n",
       "12                 1        0.0        7.0  0.060098  0.403005  0.194876   \n",
       "13                 1       -0.2        0.9  0.183494  0.480446  0.101902   \n",
       "14                 1        0.1       10.2  0.024443  0.583278  0.303529   \n",
       "15                 1       -0.3        7.9  0.062365  0.204949  0.469031   \n",
       "16                 1       -0.9        0.9  0.061210  0.213844  0.565018   \n",
       "17                 1        0.2        0.6  0.029412  0.538784  0.126322   \n",
       "18                 1        0.0        4.5  0.064522  0.673272  0.128043   \n",
       "19                 1        0.0        6.2  0.042335  0.167556  0.230380   \n",
       "20                 1        0.0        0.5  0.061712  0.371595  0.222621   \n",
       "21                 1        0.0        9.5  0.019097  0.452089  0.300201   \n",
       "22                 1       -0.3        2.2  0.006700  0.334307  0.633077   \n",
       "23                 1       -0.5        0.5  0.005190  0.596283  0.378771   \n",
       "24                 1       -0.7        0.7  0.073941  0.425250  0.088892   \n",
       "25                 1       -0.1        7.2  0.436167  0.238800  0.065062   \n",
       "26                 1        0.1        5.5  0.049648  0.647481  0.119636   \n",
       "27                 1       -0.1        3.3  0.051996  0.646988  0.176949   \n",
       "28                 1       -0.2        6.0  0.009188  0.717626  0.201197   \n",
       "29                 1        0.1        1.1  0.088471  0.568518  0.167965   \n",
       "..               ...        ...        ...       ...       ...       ...   \n",
       "969                0        0.0        0.5  0.226345  0.453557  0.096552   \n",
       "970                0        0.2        1.3  0.024619  0.319559  0.217760   \n",
       "971                0        0.0        0.5  0.282712  0.323941  0.188605   \n",
       "972                0       -0.1        2.5  0.216906  0.283249  0.148018   \n",
       "973                0        0.4        2.1  0.054085  0.187604  0.345982   \n",
       "974                0        0.0        0.0  0.014982  0.176592  0.638532   \n",
       "975                0       -0.1        0.2  0.199953  0.345909  0.357932   \n",
       "976                0        0.0        0.0  0.129444  0.017993  0.006546   \n",
       "977                0        0.3        1.0  0.145472  0.536014  0.227824   \n",
       "978                0       -0.3        0.3  0.157751  0.347512  0.203086   \n",
       "979                0        0.0        0.9  0.077426  0.386659  0.123421   \n",
       "980                0        0.0        1.5  0.138783  0.371111  0.143072   \n",
       "981                0        0.3        1.1  0.084749  0.347367  0.368720   \n",
       "982                0        0.3        0.9  0.629345  0.112256  0.037902   \n",
       "983                0       -0.1        0.5  0.038629  0.441958  0.100429   \n",
       "984                0        0.0        1.9  0.177702  0.275603  0.288981   \n",
       "985                0        0.0        0.3  0.417982  0.204106  0.130964   \n",
       "986                0        0.6        0.6  0.018274  0.101767  0.043850   \n",
       "987                0        0.3        1.3  0.191620  0.332668  0.187891   \n",
       "988                0        0.8        0.8  0.345890  0.326695  0.182883   \n",
       "989                0        0.5        3.8  0.011341  0.102522  0.460356   \n",
       "990                0       -0.1        0.4  0.128167  0.329880  0.212914   \n",
       "991                0        0.0        0.9  0.120970  0.130780  0.170057   \n",
       "992                0       -0.1        0.3  0.124256  0.339024  0.298539   \n",
       "993                0        0.7        2.3  0.436171  0.155832  0.250386   \n",
       "994                0        0.9        0.9  0.171235  0.409216  0.250323   \n",
       "995                0        0.1        0.9  0.148147  0.243434  0.391175   \n",
       "996                0        0.2        0.8  0.000326  0.005048  0.992009   \n",
       "997                0       -0.1        0.1  0.049393  0.587351  0.265013   \n",
       "998                0        0.1        1.6  0.464954  0.134678  0.199333   \n",
       "\n",
       "         fear  surprise  \n",
       "0    0.212976  0.013268  \n",
       "1    0.053174  0.005844  \n",
       "2    0.042073  0.529877  \n",
       "3    0.052193  0.004165  \n",
       "4    0.072260  0.010157  \n",
       "5    0.151320  0.011376  \n",
       "6    0.041036  0.021108  \n",
       "7    0.089212  0.023405  \n",
       "8    0.287696  0.005106  \n",
       "9    0.313891  0.020448  \n",
       "10   0.651178  0.062731  \n",
       "11   0.460811  0.015564  \n",
       "12   0.314510  0.027510  \n",
       "13   0.099603  0.134555  \n",
       "14   0.083015  0.005735  \n",
       "15   0.139498  0.124157  \n",
       "16   0.147798  0.012130  \n",
       "17   0.295618  0.009865  \n",
       "18   0.059210  0.074954  \n",
       "19   0.528680  0.031049  \n",
       "20   0.336222  0.007850  \n",
       "21   0.199263  0.029350  \n",
       "22   0.024290  0.001627  \n",
       "23   0.018904  0.000851  \n",
       "24   0.370677  0.041240  \n",
       "25   0.199143  0.060828  \n",
       "26   0.141679  0.041556  \n",
       "27   0.102591  0.021476  \n",
       "28   0.064610  0.007379  \n",
       "29   0.142541  0.032504  \n",
       "..        ...       ...  \n",
       "969  0.102569  0.120978  \n",
       "970  0.066033  0.372028  \n",
       "971  0.130815  0.073927  \n",
       "972  0.320100  0.031727  \n",
       "973  0.374047  0.038281  \n",
       "974  0.161602  0.008292  \n",
       "975  0.083776  0.012430  \n",
       "976  0.042180  0.803837  \n",
       "977  0.065264  0.025427  \n",
       "978  0.233245  0.058406  \n",
       "979  0.076374  0.336120  \n",
       "980  0.223867  0.123167  \n",
       "981  0.173133  0.026031  \n",
       "982  0.112679  0.107818  \n",
       "983  0.061052  0.357933  \n",
       "984  0.232603  0.025111  \n",
       "985  0.038363  0.208586  \n",
       "986  0.006969  0.829140  \n",
       "987  0.047858  0.239964  \n",
       "988  0.056411  0.088121  \n",
       "989  0.367947  0.057835  \n",
       "990  0.291795  0.037243  \n",
       "991  0.457238  0.120955  \n",
       "992  0.132929  0.105252  \n",
       "993  0.062061  0.095551  \n",
       "994  0.134029  0.035197  \n",
       "995  0.182366  0.034877  \n",
       "996  0.002403  0.000214  \n",
       "997  0.083078  0.015165  \n",
       "998  0.134869  0.066167  \n",
       "\n",
       "[999 rows x 10 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_df = pd.DataFrame.from_csv(\"depressionTrainSet.csv\").reset_index()\n",
    "emotions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_emo = emotions_df.loc[:,\"sentiment\":]\n",
    "y_emo = emotions_df.loc[:,\"risk_of_suicide\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emo = emotions_df.loc[:,\"sentiment\":]\n",
    "y_emo = emotions_df.loc[:,\"risk_of_suicide\"].astype(int)\n",
    "\n",
    "regr = LogisticRegression()\n",
    "regr.fit(X_emo,y_emo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Score: 0.857\tMSE:-0.143\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(regr,X_emo,y_emo)\n",
    "mse = cross_val_score(regr,X_emo,y_emo,scoring=\"neg_mean_squared_error\")\n",
    "print(f\"Logistic Regression:\\nScore: {score.mean():.3f}\\tMSE:{mse.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-DTC with max_depth 02:\tScore: 0.843\tMSE: -0.157\n",
      "B-DTC with max_depth 03:\tScore: 0.840\tMSE: -0.154\n",
      "B-DTC with max_depth 04:\tScore: 0.841\tMSE: -0.152\n",
      "B-DTC with max_depth 05:\tScore: 0.851\tMSE: -0.153\n",
      "B-DTC with max_depth 06:\tScore: 0.849\tMSE: -0.152\n",
      "B-DTC with max_depth 07:\tScore: 0.859\tMSE: -0.150\n",
      "B-DTC with max_depth 08:\tScore: 0.848\tMSE: -0.144\n",
      "B-DTC with max_depth 09:\tScore: 0.853\tMSE: -0.141\n",
      "B-DTC with max_depth 10:\tScore: 0.845\tMSE: -0.154\n",
      "B-DTC with max_depth 11:\tScore: 0.846\tMSE: -0.154\n",
      "B-DTC with max_depth 12:\tScore: 0.831\tMSE: -0.193\n",
      "B-DTC with max_depth 13:\tScore: 0.808\tMSE: -0.194\n",
      "B-DTC with max_depth 14:\tScore: 0.808\tMSE: -0.189\n",
      "B-DTC with max_depth 15:\tScore: 0.804\tMSE: -0.190\n",
      "B-DTC with max_depth 16:\tScore: 0.805\tMSE: -0.192\n",
      "B-DTC with max_depth 17:\tScore: 0.803\tMSE: -0.186\n",
      "B-DTC with max_depth 18:\tScore: 0.806\tMSE: -0.201\n",
      "B-DTC with max_depth 19:\tScore: 0.805\tMSE: -0.194\n",
      "B-DTC with max_depth 20:\tScore: 0.803\tMSE: -0.195\n",
      "B-DTC with max_depth 21:\tScore: 0.803\tMSE: -0.197\n",
      "B-DTC with max_depth 22:\tScore: 0.809\tMSE: -0.191\n",
      "B-DTC with max_depth 23:\tScore: 0.806\tMSE: -0.198\n",
      "B-DTC with max_depth 24:\tScore: 0.812\tMSE: -0.200\n",
      "B-DTC with max_depth 25:\tScore: 0.806\tMSE: -0.196\n"
     ]
    }
   ],
   "source": [
    "for depth in range(2,26):\n",
    "    boosted_dtc = AdaBoostClassifier(DecisionTreeClassifier(max_depth=depth))\n",
    "    currScore = cross_val_score(boosted_dtc,X_emo,y_emo)\n",
    "    currMSE = cross_val_score(boosted_dtc,X_emo,y_emo,scoring=\"neg_mean_squared_error\")\n",
    "    print(f\"B-DTC with max_depth {depth:02d}:\\tScore: {currScore.mean():.3f}\\tMSE: {currMSE.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X = X_emo.join(X[0:999].loc[:,\"UNKNOWN_salience\":])\n",
    "\n",
    "all_y = y[0:999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-DTC with max_depth 02:\tScore: 0.864\tMSE: -0.135\n",
      "B-DTC with max_depth 03:\tScore: 0.858\tMSE: -0.144\n",
      "B-DTC with max_depth 04:\tScore: 0.863\tMSE: -0.142\n",
      "B-DTC with max_depth 05:\tScore: 0.870\tMSE: -0.124\n",
      "B-DTC with max_depth 06:\tScore: 0.866\tMSE: -0.119\n",
      "B-DTC with max_depth 07:\tScore: 0.875\tMSE: -0.129\n",
      "B-DTC with max_depth 08:\tScore: 0.877\tMSE: -0.128\n",
      "B-DTC with max_depth 09:\tScore: 0.874\tMSE: -0.126\n",
      "B-DTC with max_depth 10:\tScore: 0.888\tMSE: -0.113\n",
      "B-DTC with max_depth 11:\tScore: 0.844\tMSE: -0.162\n",
      "B-DTC with max_depth 12:\tScore: 0.840\tMSE: -0.152\n",
      "B-DTC with max_depth 13:\tScore: 0.824\tMSE: -0.174\n",
      "B-DTC with max_depth 14:\tScore: 0.827\tMSE: -0.177\n",
      "B-DTC with max_depth 15:\tScore: 0.825\tMSE: -0.175\n",
      "B-DTC with max_depth 16:\tScore: 0.820\tMSE: -0.174\n",
      "B-DTC with max_depth 17:\tScore: 0.818\tMSE: -0.183\n",
      "B-DTC with max_depth 18:\tScore: 0.827\tMSE: -0.177\n",
      "B-DTC with max_depth 19:\tScore: 0.826\tMSE: -0.176\n",
      "B-DTC with max_depth 20:\tScore: 0.821\tMSE: -0.170\n",
      "B-DTC with max_depth 21:\tScore: 0.823\tMSE: -0.180\n",
      "B-DTC with max_depth 22:\tScore: 0.829\tMSE: -0.175\n",
      "B-DTC with max_depth 23:\tScore: 0.823\tMSE: -0.179\n",
      "B-DTC with max_depth 24:\tScore: 0.825\tMSE: -0.166\n",
      "B-DTC with max_depth 25:\tScore: 0.828\tMSE: -0.172\n"
     ]
    }
   ],
   "source": [
    "for depth in range(2,26):\n",
    "    boosted_dtc = AdaBoostClassifier(DecisionTreeClassifier(max_depth=depth))\n",
    "    currScore = cross_val_score(boosted_dtc,all_X,all_y)\n",
    "    currMSE = cross_val_score(boosted_dtc,all_X,all_y,scoring=\"neg_mean_squared_error\")\n",
    "    print(f\"B-DTC with max_depth {depth:02d}:\\tScore: {currScore.mean():.3f}\\tMSE: {currMSE.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Score: 0.865\tMSE:-0.135\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(regr,all_X,all_y)\n",
    "mse = cross_val_score(regr,all_X,all_y,scoring=\"neg_mean_squared_error\")\n",
    "print(f\"Logistic Regression:\\nScore: {score.mean():.3f}\\tMSE:{mse.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X.to_csv(\"all_X_train.csv\")\n",
    "all_y.to_csv(\"all_y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boosted_dtc.pkl']"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "boosted_dtc = AdaBoostClassifier(DecisionTreeClassifier(max_depth=10))\n",
    "boosted_dtc.fit(all_X,all_y)\n",
    "\n",
    "joblib.dump(boosted_dtc, 'boosted_dtc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "currScore = cross_val_score(boosted_dtc,all_X,all_y)\n",
    "currMSE = cross_val_score(boosted_dtc,all_X,all_y,scoring=\"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10479042, -0.10810811, -0.15963855])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currScore\n",
    "currMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = LogisticRegression()\n",
    "regr.fit(all_X,all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88888888888888884"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(all_X,all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regr.pkl']"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(regr,\"regr.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
