{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud client library\n",
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "import sys, six\n",
    "\n",
    "# Import Data Sccience libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Instantiates a client\n",
    "client = language.LanguageServiceClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_suicide_df = pd.DataFrame.from_csv(\"sample_suicide_watch_text.csv\",encoding = \"ISO-8859-1\").iloc[0:10,:]\n",
    "\n",
    "small_suicide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_text(text):\n",
    "    \"\"\"Detects sentiment in the text.\"\"\"\n",
    "    client = language.LanguageServiceClient()\n",
    "\n",
    "    if isinstance(text, six.binary_type):\n",
    "        text = text.decode('utf-8')\n",
    "\n",
    "    # Instantiates a plain text document.\n",
    "    document = types.Document(\n",
    "        content=text,\n",
    "        type=enums.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "    # Detects sentiment in the document. You can also analyze HTML with:\n",
    "    #   document.type == enums.Document.Type.HTML\n",
    "    sentiment = client.analyze_sentiment(document).document_sentiment\n",
    "    \n",
    "    return [sentiment.score,sentiment.magnitude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_sentiment_text(text):\n",
    "    \"\"\"Detects entity sentiment in the provided text.\"\"\"\n",
    "    client = language.LanguageServiceClient()\n",
    "\n",
    "    if isinstance(text, six.binary_type):\n",
    "        text = text.decode('utf-8')\n",
    "\n",
    "    document = types.Document(\n",
    "        content=text.encode('utf-8'),\n",
    "        type=enums.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "    # Detect and send native Python encoding to receive correct word offsets.\n",
    "    encoding = enums.EncodingType.UTF32\n",
    "    if sys.maxunicode == 65535:\n",
    "        encoding = enums.EncodingType.UTF16\n",
    "\n",
    "    result = client.analyze_entity_sentiment(document, encoding)\n",
    "\n",
    "    for entity in result.entities:\n",
    "        print('Mentions: ')\n",
    "        print(u'Name: \"{}\"'.format(entity.name))\n",
    "        for mention in entity.mentions:\n",
    "            print(u'  Begin Offset : {}'.format(mention.text.begin_offset))\n",
    "            print(u'  Content : {}'.format(mention.text.content))\n",
    "            print(u'  Magnitude : {}'.format(mention.sentiment.magnitude))\n",
    "            print(u'  Sentiment : {}'.format(mention.sentiment.score))\n",
    "            print(u'  Type : {}'.format(mention.type))\n",
    "        print(u'Salience: {}'.format(entity.salience))\n",
    "        print(u'Sentiment: {}\\n'.format(entity.sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mentions: \n",
      "Name: \"words\"\n",
      "  Begin Offset : 57\n",
      "  Content : words\n",
      "  Magnitude : 0.0\n",
      "  Sentiment : 0.0\n",
      "  Type : 2\n",
      "Salience: 0.3393266499042511\n",
      "Sentiment: \n",
      "\n",
      "Mentions: \n",
      "Name: \"misconception\"\n",
      "  Begin Offset : 199\n",
      "  Content : misconception\n",
      "  Magnitude : 0.800000011920929\n",
      "  Sentiment : -0.800000011920929\n",
      "  Type : 2\n",
      "Salience: 0.19303403794765472\n",
      "Sentiment: magnitude: 1.600000023841858\n",
      "score: -0.800000011920929\n",
      "\n",
      "\n",
      "Mentions: \n",
      "Name: \"anyone\"\n",
      "  Begin Offset : 330\n",
      "  Content : anyone\n",
      "  Magnitude : 0.30000001192092896\n",
      "  Sentiment : -0.30000001192092896\n",
      "  Type : 2\n",
      "Salience: 0.09136639535427094\n",
      "Sentiment: magnitude: 0.699999988079071\n",
      "score: -0.30000001192092896\n",
      "\n",
      "\n",
      "Mentions: \n",
      "Name: \"attention\"\n",
      "  Begin Offset : 144\n",
      "  Content : attention\n",
      "  Magnitude : 0.0\n",
      "  Sentiment : 0.0\n",
      "  Type : 2\n",
      "Salience: 0.09088879823684692\n",
      "Sentiment: \n",
      "\n",
      "Mentions: \n",
      "Name: \"pain\"\n",
      "  Begin Offset : 218\n",
      "  Content : pain\n",
      "  Magnitude : 0.20000000298023224\n",
      "  Sentiment : -0.20000000298023224\n",
      "  Type : 2\n",
      "Salience: 0.05292052775621414\n",
      "Sentiment: magnitude: 0.20000000298023224\n",
      "score: -0.20000000298023224\n",
      "\n",
      "\n",
      "Mentions: \n",
      "Name: \"feelings\"\n",
      "  Begin Offset : 240\n",
      "  Content : feelings\n",
      "  Magnitude : 0.6000000238418579\n",
      "  Sentiment : -0.6000000238418579\n",
      "  Type : 2\n",
      "Salience: 0.04622408002614975\n",
      "Sentiment: magnitude: 0.6000000238418579\n",
      "score: -0.6000000238418579\n",
      "\n",
      "\n",
      "Mentions: \n",
      "Name: \"assumption\"\n",
      "  Begin Offset : 188\n",
      "  Content : assumption\n",
      "  Magnitude : 0.10000000149011612\n",
      "  Sentiment : -0.10000000149011612\n",
      "  Type : 2\n",
      "Salience: 0.04348456487059593\n",
      "Sentiment: magnitude: 0.10000000149011612\n",
      "score: -0.10000000149011612\n",
      "\n",
      "\n",
      "Mentions: \n",
      "Name: \"feelings\"\n",
      "  Begin Offset : 477\n",
      "  Content : feelings\n",
      "  Magnitude : 0.20000000298023224\n",
      "  Sentiment : -0.20000000298023224\n",
      "  Type : 2\n",
      "Salience: 0.033725421875715256\n",
      "Sentiment: magnitude: 0.20000000298023224\n",
      "score: -0.20000000298023224\n",
      "\n",
      "\n",
      "Mentions: \n",
      "Name: \"persistence\"\n",
      "  Begin Offset : 444\n",
      "  Content : persistence\n",
      "  Magnitude : 0.8999999761581421\n",
      "  Sentiment : -0.8999999761581421\n",
      "  Type : 2\n",
      "Salience: 0.029522333294153214\n",
      "Sentiment: magnitude: 0.8999999761581421\n",
      "score: -0.8999999761581421\n",
      "\n",
      "\n",
      "Mentions: \n",
      "Name: \"ideations\"\n",
      "  Begin Offset : 486\n",
      "  Content : ideations\n",
      "  Magnitude : 0.10000000149011612\n",
      "  Sentiment : -0.10000000149011612\n",
      "  Type : 2\n",
      "Salience: 0.029522333294153214\n",
      "Sentiment: magnitude: 0.10000000149011612\n",
      "score: -0.10000000149011612\n",
      "\n",
      "\n",
      "Mentions: \n",
      "Name: \"thoughts\"\n",
      "  Begin Offset : 468\n",
      "  Content : thoughts\n",
      "  Magnitude : 0.4000000059604645\n",
      "  Sentiment : -0.4000000059604645\n",
      "  Type : 2\n",
      "Salience: 0.029522333294153214\n",
      "Sentiment: magnitude: 0.4000000059604645\n",
      "score: -0.4000000059604645\n",
      "\n",
      "\n",
      "Mentions: \n",
      "Name: \"myself.\"\n",
      "  Begin Offset : 519\n",
      "  Content : myself.\n",
      "  Magnitude : 0.0\n",
      "  Sentiment : 0.0\n",
      "  Type : 2\n",
      "Salience: 0.020462526008486748\n",
      "Sentiment: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "entity_sentiment_text(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_data = []\n",
    "\n",
    "for record in small_suicide_df.iterrows():\n",
    "    text = record[1][\"text\"]\n",
    "    \n",
    "    extra_record = sentiment_text(text)\n",
    "    extra_data.append(extra_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_data_df = pd.DataFrame(extra_data, columns=[\"Score\",\"Magnitude\"],index=small_suicide_df.index)\n",
    "\n",
    "extra_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_combined_df = small_suicide_df.join(extra_data_df)\n",
    "\n",
    "small_combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "depression_df = pd.DataFrame.from_csv(\"depressionTrainingSet3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep500_df = depression_df.iloc[0:500,0:1].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep500_extra = []\n",
    "\n",
    "for record in dep500_df.iterrows():\n",
    "    text = record[1][\"text\"]\n",
    "    \n",
    "    extra_record = sentiment_text(text)\n",
    "    dep500_extra.append(extra_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep500_extra_df = pd.DataFrame(dep500_extra,columns=[\"sentiment\",\"magnitude\"])\n",
    "\n",
    "dep500_extra_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "big_dep500_df = dep500_df.join(dep500_extra_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = big_dep500_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start doing classification with SKlearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:,[\"sentiment\",\"magnitude\"]]\n",
    "y = df.loc[:,\"risk_of_suicide\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the non-suicide data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
